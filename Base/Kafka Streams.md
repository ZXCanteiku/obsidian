## Что такое Kafka Streams
aliases: 
	- ""

---

### Kafka Streams — это библиотека для обработки потоковых данных в реальном времени, построенная поверх Apache Kafka. Она позволяет создавать приложения и микросервисы, которые преобразуют, анализируют и обогащают данные прямо в процессе их движения через Kafka. Вот ключевые особенности и отличия от "обычной" Kafka:

---

### **Основные особенности Kafka Streams**

1. **Потоковая обработка данных**:
    - Поддержка операций: фильтрация, агрегация, соединение потоков, оконные операции (например, подсчет метрик за последние 5 минут).
    - Возможность объединять данные из нескольких топиков (join) и обрабатывать их как таблицы (KStream + KTable).

2. **Гибкая семантика**:
    - Точно-однократная обработка (**Exactly-Once Semantics**) за счет интеграции с транзакционными продюсерами/консьюмерами.
    - Автоматическое управление смещениями (offsets) и восстановление после сбоев.
3. **Управление состоянием**:
    - Локальные хранилища (**State Stores**) для сохранения промежуточных данных (например, счетчиков, агрегаций).
    - Возможность использовать **RocksDB** или in-memory хранилища.
4. **Масштабируемость**:
    - Горизонтальное масштабирование: обработка распределяется по партициям Kafka.
    - Перераспределение нагрузки при добавлении/удалении инстансов приложения.
5. **DSL и Processor API**:
    - **Высокоуровневый DSL** (напоминает функциональный стиль):  
```java
KStream<String, String> stream = builder.stream("input-topic");
stream.filter((k, v) -> v.length() > 10)
      .groupByKey()
      .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
      .count()
      .toStream()
      .to("output-topic");
```
-  **Низкоуровневый Processor API** для кастомной логики.
        

---
### **Разница между Kafka Streams и обычной Kafka**

|**Аспект**|**Обычная Kafka**|**Kafka Streams**|
|---|---|---|
|**Роль**|Транспортировка данных (обмен сообщениями).|Обработка данных в реальном времени.|
|**Уровень абстракции**|Низкоуровневый API (Producer/Consumer).|Высокоуровневый API для построения пайплайнов.|
|**Управление состоянием**|Нет встроенной поддержки (требуются внешние БД).|Встроенные State Stores для хранения состояния.|
|**Обработка данных**|Консьюмеры читают сообщения по одному.|Операции над потоками: агрегации, joins, окна.|
|**Гарантии доставки**|At-least-once/At-most-once (без доп. настроек).|Exactly-Once из коробки.|
|**Масштабирование**|Через консьюмерные группы.|Автоматическое распределение партиций между инстансами.|
|**Примеры использования**|Передача событий, логирование, очереди задач.|Аналитика в реальном времени, ETL, обогащение данных.|

---

### **Примеры задач, которые решает Kafka Streams**

1. **Агрегация данных**:
    - Подсчет количества кликов пользователя за последний час.
    - Вычисление среднего значения метрики (например, температуры датчика) в окне времени.
2. **Объединение потоков**:
    - Обогащение данных о заказах информацией о пользователях из другого топика.
3. **Обработка аномалий**:
    - Обнаружение подозрительных транзакций в реальном времени.
4. **Трансформация данных**:
    - Конвертация формата сообщений (JSON → Avro) или фильтрация невалидных данных.

---

### **Когда использовать Kafka Streams?**
- Если нужна **сложная обработка потоковых данных** (агрегации, joins, окна).
- Когда важно **минимизировать задержки** (данные обрабатываются сразу, без сохранения во внешние системы).
- Для упрощения архитектуры: обработка происходит внутри приложения, без подключения внешних фреймворков (вроде Apache Flink).

---

### **Архитектура Kafka Streams**

1. **Топология (Topology)**:
    - Граф обработки данных, состоящий из **источников** (input topics), **процессоров** (логика) и **приемников** (output topics).
2. **Task**:
    - Единица параллелизма. Каждая задача обрабатывает данные из определенной партиции.
3. **Stream Threads**:
    - Потоки выполнения, управляющие задачами. Их количество настраивается через `num.stream.threads`.

---

### **Ограничения Kafka Streams**

- **Только для Kafka**: Не работает с другими системами (например, RabbitMQ).
- **Сложность для кастомных сценариев**: Некоторые операции проще реализовать через низкоуровневый Consumer API.
- **Зависимость от партиций**: Параллелизм обработки определяется количеством партиций в топике.

---

### **Пример приложения на Kafka Streams**

```java
Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "word-count-app");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");

StreamsBuilder builder = new StreamsBuilder();
KStream<String, String> textLines = builder.stream("text-topic");

textLines
  .flatMapValues(line -> Arrays.asList(line.toLowerCase().split(" ")))
  .groupBy((key, word) -> word)
  .count(Materialized.as("word-count-store"))
  .toStream()
  .to("word-count-output", Produced.with(Serdes.String(), Serdes.Long()));

KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();
```

---
### **Заключение**

Kafka Streams расширяет возможности Kafka, добавляя инструменты для **потоковой обработки данных** без необходимости использовать внешние системы. Если ваша задача требует сложных преобразований, агрегаций или работы с окнами — это идеальный выбор. Для простых сценариев (например, пересылка сообщений) достаточно стандартных продюсеров и консьюмеров.

---
Tags: #infrastructure #kafka
Author: [[]]
Related: [[Инфраструктурными технологии для разработки на Java]]
URL: -- 
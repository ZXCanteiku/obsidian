
### 1. С какими версиями Java работал? Был ли опыт миграции с одной версии на другую

- Работал с 11 и 17 версией java
- **Java 8**: Главное нововведение — лямбда-выражения и Stream API, что позволило писать более декларативный и функциональный код, упрощая обработку коллекций.
- **Java 11**: В этой версии появились улучшения в API для работы со строками и коллекциями, а также оптимизации, направленные на повышение производительности.
- **Java 17**: Добавление таких возможностей, как sealed classes и pattern matching, значительно повысило безопасность и структурированность кода, а также позволило ограничить наследование и улучшить читаемость архитектуры.»

Особо никаких проблем не возникло при переходи с 11 в 17 версию, просто пришлось переписать некоторые depleted методы

---

### 2. Разница между версиями Java?

- **Java 8**: Главное нововведение — лямбда-выражения и Stream API, что позволило писать более декларативный и функциональный код, упрощая обработку коллекций.
- **Java 11**: В этой версии появились улучшения в API для работы со строками и коллекциями, а также оптимизации, направленные на повышение производительности.
- **Java 17**: Добавление таких возможностей, как sealed classes и pattern matching, значительно повысило безопасность и структурированность кода, а также позволило ограничить наследование и улучшить читаемость архитектуры.»
- Java 21: Добавлены и улучшены зеленные потоки

---

### 3. Для каких задач нужна Shenandoah GC и когда её лучше не использовать?

- Shenandoah GC — это сборщик мусора с низкими паузами, разработанный для минимизации времени остановок приложения за счёт параллельной работы сборщика. Он особенно полезен для приложений с высокими требованиями к задержкам, таких как системы реального времени или высоконагруженные сервисы, где важна стабильная и быстрая обработка запросов.

Не стоит применять:
Применение Shenandoah GC может быть избыточным для небольших или менее критичных приложений, где задержки не являются критическим фактором. Кроме того, если приложение имеет узкие места в логике работы или не может эффективно распределять нагрузку между потоками, стандартные сборщики мусора могут работать быстрее и проще в настройке.

---

### 4. Какая версия Spring и Spring Boot в текущем проекте?

- На проекте версия spring boot 3 и Spring

---
### 5. Зачем нужен Spring Boot Starter и был ли опыт написания?

1. **Упрощение управления зависимостями**
	 - Агрегация библиотек
	 - Консистентность версий
2. Автоматическая конфигурация
	  - Меньше конфигурации вручную
	  - Быстрый старт проекта:
3. Стандартизация и расширяемость

### Как создать собственный Spring Boot Starter

Если вам необходимо создать свой стартер (например, для инкапсуляции часто используемой в вашей организации функциональности), можно следовать следующим шагам:

#### 1. Создание Maven/Gradle проекта

- **Инициализация проекта:** Создайте новый проект, который будет содержать библиотеки и настройки, необходимые для вашего стартер.
- **Добавление зависимостей:** В `pom.xml` (или `build.gradle`) укажите зависимости, которые понадобятся для работы авто-конфигурации. Обычно это `spring-boot-autoconfigure` и `spring-boot-starter`.

#### 2. Реализация авто-конфигурации

- **Создание класса конфигурации:** Напишите класс, помеченный аннотацией `@Configuration`, который будет содержать определения бинов. При необходимости используйте аннотации типа `@ConditionalOnClass`, `@ConditionalOnMissingBean` и прочие для более тонкой настройки авто-конфигурации.

#### 3. Регистрация авто-конфигурации

- **Создание файла `spring.factories`:** В директории `src/main/resources/META-INF/` создайте файл `spring.factories` и добавьте в него запись, которая укажет Spring Boot, где искать класс авто-конфигурации.
```java
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
com.example.autoconfig.MyCustomAutoConfiguration
```
Этот файл является ключевым элементом, позволяющим Spring Boot автоматически применять конфигурацию при наличии вашего стартер.

---
### 6. Самая сложная техническая задача?

--

---
### 7. Kotlin co-routines?

Использовал пару раз. Из последних кейсов

Где по закрытию опер дня, нужно было из бд вытянуть все активные Корпоративные Действия  и по ним получить остатки, и после этого их нужно было отправить потребителям в качестве участников.
В этом кейсе использовал `Dispatchers.IO` co-routines.

Почему `Dispatchers.IO`
 - Позволило **Сохранить основные потоки для бизнес-логики**.
 - **Обрабатывать больше участников одновременно без блокировки**.
 - То что  потоки расширяются динамически 

---
### 8. Блокирующие операции в Project Reactor?

В Project Reactor блокирующие операции – это вызовы, которые могут приостанавливать поток выполнения в реактивной цепочке. Это негативно сказывается на производительности, так как блокируются ресурсы, предназначенные для обработки асинхронных событий. Чтобы минимизировать их влияние, используют специальные Schedulers, позволяющие изолировать блокирующие вызовы от основной реактивной цепочки.

---
### 9. С чем работал из Observability?

- Prometheus и Grafana для мониторинга метрик.
- Elasticsearch и fluint bit

---
### 10. Tracing (Zipkin)?

-- 

---
### 11. Есть ли понимание архитектуры Kubernetes?

 - [[Архитектура Kubernetes]]
 - [[Архитектура Istio]]

---
### 12. С чем из Spring Cloud работал? Был ли опыт с Config Server?

На проекте:
- Spring cloud sleuth для трассировки

В пет проектах:
- Spring cloud Eureka для сервис-дискавери
- Api Gateway  для маршутизации и балансировки запросов 

---
### 13. Неконсистентность данных в Redis?

Для минимизации проблем с неконсистентностью данных в Redis и обеспечения целостности можно применять следующие подходы и паттерны:

#### 1. Синхронизация репликации
- **Команда WAIT:**  
    Позволяет заставить Redis дождаться репликации операции на указанное количество реплицированных узлов. Например, команда `WAIT 2 1000` гарантирует, что данные будут записаны как минимум на двух репликах в течение 1000 мс, что помогает уменьшить вероятность чтения устаревших данных.
#### 2. Атомарные операции
- **LUA-скрипты:**  
    Использование скриптов на языке LUA позволяет выполнять несколько команд атомарно. Это гарантирует, что сложные операции не будут прерваны другими запросами, что важно для обеспечения консистентности при выполнении последовательности операций.
#### 3. Транзакционные механизмы
- **Комбинация WATCH/MULTI/EXEC:**  
    Этот механизм реализует оптимистическую блокировку. С помощью команды `WATCH` можно следить за изменениями ключей, а затем группировать последовательность команд в транзакцию с помощью `MULTI` и `EXEC`. Если один из отслеживаемых ключей изменится до выполнения `EXEC`, транзакция будет отклонена, что позволяет избежать конфликтов при конкурентном доступе.
#### 4. Надёжность сохранения данных
- **Настройка AOF и RDB:**
    - **AOF (Append Only File):** При использовании AOF можно настроить режим fsync для записи данных на диск с разной частотой (например, каждые секунды или на каждом изменении), что снижает риск потери данных в случае сбоя.
    - **RDB-снимки:** Регулярное создание снимков памяти помогает иметь резервное копирование состояния базы, что может быть полезно для восстановления данных.
#### 5. Обработка ошибок на уровне приложения
- **Проверки и компенсационные операции:**  
    Если данные критичны, приложение может самостоятельно реализовать дополнительные проверки целостности. Например, можно запускать фоновые процессы для сверки данных или применять компенсационные транзакции для исправления расхождений.
#### 6. Использование архитектурных паттернов
- **CQRS (Command Query Responsibility Segregation):**  
    Разделение операций записи и чтения позволяет использовать Redis как быстрый кэш, а для обеспечения целостности данных основным источником правды применять другую систему (например, SQL или другую NoSQL базу данных).
- **Event Sourcing:**  
    Сохранение всех изменений состояния в виде событий может помочь восстановить или синхронизировать данные в случае возникновения расхождений.

---
### 14. Для чего использовал MongoDB?

--

---
### 15. Как повысить пропускную способность инстанса Kafka?

- **Увеличение числа партиций:**  
    Распределите нагрузку, увеличив число партиций в топиках. Это позволит параллельно обрабатывать данные как на стороне продюсеров, так и на стороне консьюмеров.
- **Настройка параметров продюсера:**
    - **`batch.size` и `linger.ms:`** Увеличение размера пакета (batch size) и настройка времени ожидания (linger.ms) позволяет отправлять данные пакетами, что снижает накладные расходы на сетевое взаимодействие.
    - **Сжатие:** Используйте сжатие (например, gzip или lz4), чтобы уменьшить объём передаваемых данных, при этом балансируя между степенью сжатия и нагрузкой на процессор.
- **Настройка параметров брокера:**
    - **`socket.send.buffer.bytes` и `socket.receive.buffer.bytes:`** Оптимизируйте размеры буферов для сетевых соединений, чтобы обеспечить более эффективную передачу данных.
    - **`log.flush.interval.messages` и` log.flush.interval.ms:`** Настройка этих параметров позволяет контролировать частоту сброса данных на диск, что может снизить нагрузку на файловую систему.
- **Настройка параметров консьюмера:**
    - **`fetch.min.bytes` и `fetch.max.wait.ms:`** Эти параметры влияют на объём и время ожидания получения данных, что помогает оптимизировать обработку большого объёма сообщений.
- **Горизонтальное масштабирование:**  
    Добавление дополнительных брокеров в кластер позволяет распределить нагрузку по нескольким серверам, снижая нагрузку на отдельный инстанс и повышая общую производительность.
- **Распределённое хранение данных:**  
    Правильное распределение партиций по брокерам помогает снизить нагрузку на отдельные узлы. Следует учитывать балансировку по дисковому пространству и нагрузке CPU.
- **Изоляция критичных потоков:**  
    Если у вас есть разные типы нагрузок (например, OLTP и аналитика), разделите их на отдельные топики или даже кластеры, чтобы одна нагрузка не мешала другой.

---
### 16. Интеграционное тестирование 

--

---
### 17. Был ли опыт написания сложных SQL?

--

---